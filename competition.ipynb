{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Student Information\n",
    "Name: Edwin Sanjaya\n",
    "\n",
    "Student ID: 110065710\n",
    "\n",
    "GitHub ID: edwinsanjaya\n",
    "\n",
    "Kaggle name: Edwin Sanjaya 陳潤烈\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)\n",
    "\n",
    "\n",
    "## Assignment 2 & 3\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm2022-isa5810-lab2-homework) regarding Emotion Recognition on Twitter by this link https://www.kaggle.com/t/2b0d14a829f340bc88d2660dc602d4bd. The scoring will be given according to your place in the Private Leaderboard ranking:\n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)\n",
    "    Submit your last submission __BEFORE the deadline (Nov. 22th 11:59 pm, Tuesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Read and Explore the Data\n",
    "\n",
    "The first step to work with the assignment is by reading the dataset that will be used in our lab. Pandas data frame will be used to store the data since it provide robust data structure and container to work on data analysis and data science\n",
    "\n",
    "These are the file that we are working on:\n",
    "- **data_identification.csv** provides information whether a certain tweet_id is a training or test dataset\n",
    "- **emotion.csv** provides emotion label of certain tweet_id. only training dataset has the labelled emotion, test dataset has null value and will be used to assess the model performance in Kaggle competition\n",
    "- **tweets_DM.json** provides the dataset of tweets in twitter in JSON format\n",
    "\n",
    "Sample of tweets_DM.json data:\n",
    "```\n",
    "{\n",
    "  \"_score\": 391,\n",
    "  \"_index\": \"hashtag_tweets\",\n",
    "  \"_source\": {\n",
    "    \"tweet\": {\n",
    "      \"hashtags\": [\n",
    "        \"Snapchat\"\n",
    "      ],\n",
    "      \"tweet_id\": \"0x376b20\",\n",
    "      \"text\": \"People who post \\\"add me on #Snapchat\\\" must be dehydrated. Cuz man.... that's <LH>\"\n",
    "    }\n",
    "  },\n",
    "  \"_crawldate\": \"2015-05-23 11:42:47\",\n",
    "  \"_type\": \"tweets\"\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1 Reading the CSV files\n",
    "\n",
    "**data_identification.csv** and **emotion.csv** file can be directly loaded without further processing since CSV files already in table format"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "         tweet_id identification\n0        0x28cc61           test\n1        0x29e452          train\n2        0x2b3819          train\n3        0x2db41f           test\n4        0x2a2acc          train\n...           ...            ...\n1867530  0x227e25          train\n1867531  0x293813          train\n1867532  0x1e1a7e          train\n1867533  0x2156a5          train\n1867534  0x2bb9d2          train\n\n[1867535 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>identification</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x28cc61</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x29e452</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x2b3819</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x2db41f</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x2a2acc</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1867530</th>\n      <td>0x227e25</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1867531</th>\n      <td>0x293813</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1867532</th>\n      <td>0x1e1a7e</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1867533</th>\n      <td>0x2156a5</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1867534</th>\n      <td>0x2bb9d2</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>1867535 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "kaggle_folder = os.path.join(os.getcwd(), 'kaggle_data')\n",
    "\n",
    "# Function to generate DataFrame via CSV filename\n",
    "def df_from_csv(filename):\n",
    "    f = os.path.join(kaggle_folder, filename)\n",
    "    return pd.read_csv(f, delimiter='\\t|\\n|,', engine='python')\n",
    "\n",
    "# Generate DataFrame\n",
    "data_identification = df_from_csv('data_identification.csv')\n",
    "emotion = df_from_csv('emotion.csv')\n",
    "data_identification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "         tweet_id       emotion\n0        0x3140b1       sadness\n1        0x368b73       disgust\n2        0x296183  anticipation\n3        0x2bd6e1           joy\n4        0x2ee1dd  anticipation\n...           ...           ...\n1455558  0x38dba0           joy\n1455559  0x300ea2           joy\n1455560  0x360b99          fear\n1455561  0x22eecf           joy\n1455562  0x2fb282  anticipation\n\n[1455563 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x3140b1</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x368b73</td>\n      <td>disgust</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x296183</td>\n      <td>anticipation</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x2bd6e1</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x2ee1dd</td>\n      <td>anticipation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455558</th>\n      <td>0x38dba0</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1455559</th>\n      <td>0x300ea2</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1455560</th>\n      <td>0x360b99</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>1455561</th>\n      <td>0x22eecf</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1455562</th>\n      <td>0x2fb282</td>\n      <td>anticipation</td>\n    </tr>\n  </tbody>\n</table>\n<p>1455563 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.2 Reading JSON file\n",
    "\n",
    "Unlike CSV files, the JSON files contains the tweets data in nested JSON format. There are two major problem in the format:\n",
    "1. The JSON objects in the file separated by the newline, which is not supported by pandas reader\n",
    "2. The ```_source``` key contains nested object. Using ```pd.read_json``` or ```pd.DataFrame``` directly will cause the whole nested objects stored in one attribute.\n",
    "\n",
    "To solve the problem, two approaches was used:\n",
    "1. We iterate the JSON file line by line\n",
    "2. Pandas ```pd.json_normalize``` were used to convert the nested JSON into flat JSON (one level)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "       _score          _index  \\\ntweet     391  hashtag_tweets   \n\n                                                 _source           _crawldate  \\\ntweet  {'hashtags': ['Snapchat'], 'tweet_id': '0x376b...  2015-05-23 11:42:47   \n\n        _type  \ntweet  tweets  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_score</th>\n      <th>_index</th>\n      <th>_source</th>\n      <th>_crawldate</th>\n      <th>_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tweet</th>\n      <td>391</td>\n      <td>hashtag_tweets</td>\n      <td>{'hashtags': ['Snapchat'], 'tweet_id': '0x376b...</td>\n      <td>2015-05-23 11:42:47</td>\n      <td>tweets</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Issue in read JSON data directly: nested object in _source aggregated as one in _source field\n",
    "test_json = {\n",
    "    \"_score\": 391,\n",
    "    \"_index\": \"hashtag_tweets\",\n",
    "    \"_source\": {\n",
    "        \"tweet\": {\n",
    "            \"hashtags\": [\n",
    "                \"Snapchat\"\n",
    "            ],\n",
    "            \"tweet_id\": \"0x376b20\",\n",
    "            \"text\": \"People who post \\\"add me on #Snapchat\\\" must be dehydrated. Cuz man.... that's <LH>\"\n",
    "        }\n",
    "    },\n",
    "    \"_crawldate\": \"2015-05-23 11:42:47\",\n",
    "    \"_type\": \"tweets\"\n",
    "}\n",
    "test_json_df = pd.DataFrame(test_json)\n",
    "test_json_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of          tweet_id                                               text\n0        0x376b20  People who post \"add me on #Snapchat\" must be ...\n1        0x2d5350  @brianklaas As we see, Trump is dangerous to #...\n2        0x28b412  Confident of your obedience, I write to you, k...\n3        0x1cd5b0                Now ISSA is stalking Tasha 😂😂😂 <LH>\n4        0x2de201  \"Trust is not the same as faith. A friend is s...\n...           ...                                                ...\n1867530  0x316b80  When you buy the last 2 tickets remaining for ...\n1867531  0x29d0cb  I swear all this hard work gone pay off one da...\n1867532  0x2a6a4f  @Parcel2Go no card left when I wasn't in so I ...\n1867533  0x24faed  Ah, corporate life, where you can date <LH> us...\n1867534  0x34be8c             Blessed to be living #Sundayvibes <LH>\n\n[1867535 rows x 2 columns]>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON file, iterate line by line, store the data in list\n",
    "f = open(os.path.join(kaggle_folder, 'tweets_DM.json'))\n",
    "data = []\n",
    "for line in f:\n",
    "    data.append(json.loads(line))\n",
    "\n",
    "# Normalize nested JSON and convert to DataFrame\n",
    "tweets_dm = pd.json_normalize(data)\n",
    "\n",
    "# Rename columns in more readable format\n",
    "rename_map = {\n",
    "    '_score': 'score',\n",
    "    '_index': 'index',\n",
    "    '_crawldate' : 'date',\n",
    "    '_type': 'type',\n",
    "    '_source.tweet.hashtags': 'hashtags',\n",
    "    '_source.tweet.tweet_id': 'tweet_id',\n",
    "    '_source.tweet.text': 'text'\n",
    "}\n",
    "tweets_dm.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# Get necessary data: the tweet_id and text\n",
    "tweets_dm = tweets_dm[['tweet_id', 'text']]\n",
    "tweets_dm.head"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.3 Data Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data identification: (1867535, 2)\n",
      "Emotion: (1455563, 2)\n",
      "Tweets DM: (1867535, 2)\n"
     ]
    }
   ],
   "source": [
    "# Checking dimension (good practice :3)\n",
    "print(f'Data identification: {data_identification.shape}')\n",
    "print(f'Emotion: {emotion.shape}')\n",
    "print(f'Tweets DM: {tweets_dm.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "              tweet_id\nemotion               \nanger            39867\nanticipation    248935\ndisgust         139101\nfear             63999\njoy             516017\nsadness         193437\nsurprise         48729\ntrust           205478",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n    </tr>\n    <tr>\n      <th>emotion</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>anger</th>\n      <td>39867</td>\n    </tr>\n    <tr>\n      <th>anticipation</th>\n      <td>248935</td>\n    </tr>\n    <tr>\n      <th>disgust</th>\n      <td>139101</td>\n    </tr>\n    <tr>\n      <th>fear</th>\n      <td>63999</td>\n    </tr>\n    <tr>\n      <th>joy</th>\n      <td>516017</td>\n    </tr>\n    <tr>\n      <th>sadness</th>\n      <td>193437</td>\n    </tr>\n    <tr>\n      <th>surprise</th>\n      <td>48729</td>\n    </tr>\n    <tr>\n      <th>trust</th>\n      <td>205478</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique emotion value\n",
    "emotion.groupby('emotion').nunique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Preprocessing\n",
    "\n",
    "One of the process to improve our emotion prediction is by doing pre-processing.\n",
    "\n",
    "The following preprocessing techniques were used in this assignment:\n",
    "- Lowercase\n",
    "- Regular Expression: remove symbol, number, punctuation\n",
    "- Tokenization\n",
    "- Stopword Removal\n",
    "- Stemming\n",
    "- Lemmatization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Edwin\n",
      "[nltk_data]     Sanjaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Edwin\n",
      "[nltk_data]     Sanjaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Edwin Sanjaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Required library for pre-processing\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import preprocessor as p\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "nltk.download\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Require: python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.1 Basic Preprocessing: Lowercase, Banned Word, Regex\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Remove mention, url, symbol\n",
    "def basic_tweet_preprocess(text):\n",
    "    output = text.lower()\n",
    "    # tweet-preprocessor -> unused because of redudancy with tweet-tokenizer\n",
    "    # output = p.clean(output)\n",
    "    bw_list = ['<lh>', 'rt']\n",
    "    for bw in bw_list:\n",
    "        output = output.replace(bw, '')\n",
    "    output = re.sub(r'[!#$%^&*(),.?\":;{}|<>_]', '', output)\n",
    "    # output = re.sub(r'\\b[0-9]+\\b', '', output)\n",
    "    output = re.sub(r'(.)1+', r'1', output)\n",
    "    output = re.sub(r'[0-9]+', '', output)\n",
    "    output = re.sub(r\"'\", '', output)\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2 Tokenization\n",
    "\n",
    "Normally, we can use common build-in tokenizer in nltk which is word_tokenize. After some exploration and research nltk has build-in tokenizer which specialized on working on Twitter's text data called **TweetTokenizer()**. The specified tokenizer will be used for this lab assignment since they have the following benefits:\n",
    "- Tokenize the word just like normal tokenizer\n",
    "- Detect handles a.k.a. username info that started with @\n",
    "- Detect repeated characters\n",
    "- Detect phone numbers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def tweet_tokenize(text):\n",
    "    tt = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    return tt.tokenize(text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.3 Stopword Removal\n",
    "\n",
    "Stopword removal is an important process to reduce the number of redundant word that does not provide any clue in the emotion analysis\n",
    "\n",
    "By removing the redundant word, our model can focus on the important word and require less processing time due to the reduced amount of word"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    sw = set(stopwords.words(\"english\"))\n",
    "    output = [w for w in text if not w in sw]\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.4 Stemming"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    output = text\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    output = [stemmer.stem(w) for w in text]\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.5 Lemmatizing\n",
    "\n",
    "nltk and spacy provides lemmatization library. However a pos_tag is necessary to optimize the quality of the lemmatization process. Compared to the stemming, lemmatization also requires more processing time with relatively similar result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# def lemmatizing(text):\n",
    "#     output = []\n",
    "#     lemmatizer = nltk.WordNetLemmatizer()\n",
    "#     text_pos = pos_tag(text)\n",
    "#     for token_pos in text_pos:\n",
    "#         output.append(lemmatizer.lemmatize(token_pos[0], pos=tag_map[token_pos[1]]))\n",
    "#     return output\n",
    "\n",
    "def lemmatizing(text):\n",
    "    text = nlp(\" \".join(text))\n",
    "    output = []\n",
    "    for token in text:\n",
    "        output.append(token.lemma_)\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def join_token(list):\n",
    "    output = ' '.join(list)\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Example: Pre-processing step by step in first 5 data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   tweet_id                                               text\n0  0x376b20  People who post \"add me on #Snapchat\" must be ...\n1  0x2d5350  @brianklaas As we see, Trump is dangerous to #...\n2  0x28b412  Confident of your obedience, I write to you, k...\n3  0x1cd5b0                Now ISSA is stalking Tasha 😂😂😂 <LH>\n4  0x2de201  \"Trust is not the same as faith. A friend is s...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x376b20</td>\n      <td>People who post \"add me on #Snapchat\" must be ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x2d5350</td>\n      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x28b412</td>\n      <td>Confident of your obedience, I write to you, k...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x1cd5b0</td>\n      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x2de201</td>\n      <td>\"Trust is not the same as faith. A friend is s...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data to show step by step process\n",
    "head_tweets_dm = tweets_dm.head().copy()\n",
    "head_tweets_dm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   tweet_id                                               text\n0  0x376b20  people who post add me on snapchat must be deh...\n1  0x2d5350  @brianklaas as we see trump is dangerous to fr...\n2  0x28b412  confident of your obedience i write to you kno...\n3  0x1cd5b0                    now issa is stalking tasha 😂😂😂 \n4  0x2de201  trust is not the same as faith a friend is som...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x376b20</td>\n      <td>people who post add me on snapchat must be deh...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x2d5350</td>\n      <td>@brianklaas as we see trump is dangerous to fr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x28b412</td>\n      <td>confident of your obedience i write to you kno...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x1cd5b0</td>\n      <td>now issa is stalking tasha 😂😂😂</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x2de201</td>\n      <td>trust is not the same as faith a friend is som...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_tweets_dm['text'] = head_tweets_dm['text'].apply(lambda x: basic_tweet_preprocess(x))\n",
    "head_tweets_dm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "   tweet_id                                               text\n0  0x376b20  [people, who, post, add, me, on, snapchat, mus...\n1  0x2d5350  [as, we, see, trump, is, dangerous, to, freepr...\n2  0x28b412  [confident, of, your, obedience, i, write, to,...\n3  0x1cd5b0          [now, issa, is, stalking, tasha, 😂, 😂, 😂]\n4  0x2de201  [trust, is, not, the, same, as, faith, a, frie...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x376b20</td>\n      <td>[people, who, post, add, me, on, snapchat, mus...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x2d5350</td>\n      <td>[as, we, see, trump, is, dangerous, to, freepr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x28b412</td>\n      <td>[confident, of, your, obedience, i, write, to,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x1cd5b0</td>\n      <td>[now, issa, is, stalking, tasha, 😂, 😂, 😂]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x2de201</td>\n      <td>[trust, is, not, the, same, as, faith, a, frie...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize\n",
    "head_tweets_dm['text'] = head_tweets_dm['text'].apply(lambda x: tweet_tokenize(x))\n",
    "head_tweets_dm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "   tweet_id                                               text\n0  0x376b20  [people, post, add, snapchat, must, dehydrated...\n1  0x2d5350  [see, trump, dangerous, freepress, around, wor...\n2  0x28b412  [confident, obedience, write, knowing, even, a...\n3  0x1cd5b0                   [issa, stalking, tasha, 😂, 😂, 😂]\n4  0x2de201  [trust, faith, friend, someone, trust, putting...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x376b20</td>\n      <td>[people, post, add, snapchat, must, dehydrated...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x2d5350</td>\n      <td>[see, trump, dangerous, freepress, around, wor...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x28b412</td>\n      <td>[confident, obedience, write, knowing, even, a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x1cd5b0</td>\n      <td>[issa, stalking, tasha, 😂, 😂, 😂]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x2de201</td>\n      <td>[trust, faith, friend, someone, trust, putting...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop word\n",
    "head_tweets_dm['text'] = head_tweets_dm['text'].apply(lambda x: remove_stopwords(x))\n",
    "head_tweets_dm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   tweet_id                                               text\n0  0x376b20  [peopl, post, add, snapchat, must, dehydr, cuz...\n1  0x2d5350  [see, trump, danger, freepress, around, world,...\n2  0x28b412  [confid, obedi, write, know, even, ask, philem...\n3  0x1cd5b0                      [issa, stalk, tasha, 😂, 😂, 😂]\n4  0x2de201  [trust, faith, friend, someon, trust, put, fai...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x376b20</td>\n      <td>[peopl, post, add, snapchat, must, dehydr, cuz...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x2d5350</td>\n      <td>[see, trump, danger, freepress, around, world,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x28b412</td>\n      <td>[confid, obedi, write, know, even, ask, philem...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x1cd5b0</td>\n      <td>[issa, stalk, tasha, 😂, 😂, 😂]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x2de201</td>\n      <td>[trust, faith, friend, someon, trust, put, fai...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stem\n",
    "head_tweets_dm['text'] = head_tweets_dm['text'].apply(lambda x: stemming(x))\n",
    "head_tweets_dm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   tweet_id                                               text\n0  0x376b20  [peopl, post, add, snapchat, must, dehydr, cuz...\n1  0x2d5350  [see, trump, danger, freepress, around, world,...\n2  0x28b412  [confid, obedi, write, know, even, ask, philem...\n3  0x1cd5b0                      [issa, stalk, tasha, 😂, 😂, 😂]\n4  0x2de201  [trust, faith, friend, someon, trust, put, fai...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x376b20</td>\n      <td>[peopl, post, add, snapchat, must, dehydr, cuz...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x2d5350</td>\n      <td>[see, trump, danger, freepress, around, world,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x28b412</td>\n      <td>[confid, obedi, write, know, even, ask, philem...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x1cd5b0</td>\n      <td>[issa, stalk, tasha, 😂, 😂, 😂]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x2de201</td>\n      <td>[trust, faith, friend, someon, trust, put, fai...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemma\n",
    "head_tweets_dm['text'] = head_tweets_dm['text'].apply(lambda x: lemmatizing(x))\n",
    "head_tweets_dm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "         tweet_id                                               text\n0        0x376b20  people who post add me on snapchat must be deh...\n1        0x2d5350  @brianklaas as we see trump is dangerous to fr...\n2        0x28b412  confident of your obedience i write to you kno...\n3        0x1cd5b0                    now issa is stalking tasha 😂😂😂 \n4        0x2de201  trust is not the same as faith a friend is som...\n...           ...                                                ...\n1867530  0x316b80  when you buy the last  tickets remaining for a...\n1867531  0x29d0cb  i swear all this hard work gone pay off one da...\n1867532  0x2a6a4f  @parcelgo no card left when i wasnt in so i ha...\n1867533  0x24faed  ah corporate life where you can date  using ju...\n1867534  0x34be8c                  blessed to be living sundayvibes \n\n[1867535 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x376b20</td>\n      <td>people who post add me on snapchat must be deh...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x2d5350</td>\n      <td>@brianklaas as we see trump is dangerous to fr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x28b412</td>\n      <td>confident of your obedience i write to you kno...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x1cd5b0</td>\n      <td>now issa is stalking tasha 😂😂😂</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x2de201</td>\n      <td>trust is not the same as faith a friend is som...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1867530</th>\n      <td>0x316b80</td>\n      <td>when you buy the last  tickets remaining for a...</td>\n    </tr>\n    <tr>\n      <th>1867531</th>\n      <td>0x29d0cb</td>\n      <td>i swear all this hard work gone pay off one da...</td>\n    </tr>\n    <tr>\n      <th>1867532</th>\n      <td>0x2a6a4f</td>\n      <td>@parcelgo no card left when i wasnt in so i ha...</td>\n    </tr>\n    <tr>\n      <th>1867533</th>\n      <td>0x24faed</td>\n      <td>ah corporate life where you can date  using ju...</td>\n    </tr>\n    <tr>\n      <th>1867534</th>\n      <td>0x34be8c</td>\n      <td>blessed to be living sundayvibes</td>\n    </tr>\n  </tbody>\n</table>\n<p>1867535 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential pre-processing\n",
    "tweets_dm['text'] = tweets_dm['text'].apply(lambda x: x.lower())\n",
    "tweets_dm['text'] = tweets_dm['text'].apply(lambda x: basic_tweet_preprocess(x))\n",
    "# tweets_dm['text'] = tweets_dm['text'].apply(lambda x: tweet_tokenize(x))\n",
    "# tweets_dm['text'] = tweets_dm['text'].apply(lambda x: remove_stopwords(x))\n",
    "# tweets_dm['text'] = tweets_dm['text'].apply(lambda x: stemming(x))\n",
    "# tweets_dm['text'] = tweets_dm['text'].apply(lambda x: lemmatizing(x))\n",
    "tweets_dm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "         tweet_id                                               text\n0        0x376b20  people who post add me on snapchat must be deh...\n1        0x2d5350  @brianklaas as we see trump is dangerous to fr...\n2        0x28b412  confident of your obedience i write to you kno...\n3        0x1cd5b0                    now issa is stalking tasha 😂😂😂 \n4        0x2de201  trust is not the same as faith a friend is som...\n...           ...                                                ...\n1867530  0x316b80  when you buy the last  tickets remaining for a...\n1867531  0x29d0cb  i swear all this hard work gone pay off one da...\n1867532  0x2a6a4f  @parcelgo no card left when i wasnt in so i ha...\n1867533  0x24faed  ah corporate life where you can date  using ju...\n1867534  0x34be8c                  blessed to be living sundayvibes \n\n[1867535 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x376b20</td>\n      <td>people who post add me on snapchat must be deh...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x2d5350</td>\n      <td>@brianklaas as we see trump is dangerous to fr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x28b412</td>\n      <td>confident of your obedience i write to you kno...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x1cd5b0</td>\n      <td>now issa is stalking tasha 😂😂😂</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x2de201</td>\n      <td>trust is not the same as faith a friend is som...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1867530</th>\n      <td>0x316b80</td>\n      <td>when you buy the last  tickets remaining for a...</td>\n    </tr>\n    <tr>\n      <th>1867531</th>\n      <td>0x29d0cb</td>\n      <td>i swear all this hard work gone pay off one da...</td>\n    </tr>\n    <tr>\n      <th>1867532</th>\n      <td>0x2a6a4f</td>\n      <td>@parcelgo no card left when i wasnt in so i ha...</td>\n    </tr>\n    <tr>\n      <th>1867533</th>\n      <td>0x24faed</td>\n      <td>ah corporate life where you can date  using ju...</td>\n    </tr>\n    <tr>\n      <th>1867534</th>\n      <td>0x34be8c</td>\n      <td>blessed to be living sundayvibes</td>\n    </tr>\n  </tbody>\n</table>\n<p>1867535 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join token as whole\n",
    "# tweets_dm['text'] = tweets_dm['text'].apply(lambda x: join_token(x))\n",
    "tweets_dm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Feature Extraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "         tweet_id                                               text  \\\n0        0x376b20  people who post add me on snapchat must be deh...   \n1        0x2d5350  @brianklaas as we see trump is dangerous to fr...   \n2        0x1cd5b0                    now issa is stalking tasha 😂😂😂    \n3        0x1d755c  @riskshow @thekevinallison thx for the best ti...   \n4        0x2c91a8            still waiting on those supplies liscus    \n...           ...                                                ...   \n1455558  0x321566  im so happy nowonder the name of this show hap...   \n1455559  0x38959e  in every circumtance id like to be thankful to...   \n1455560  0x2cbca6  theres currently two girls walking around the ...   \n1455561  0x24faed  ah corporate life where you can date  using ju...   \n1455562  0x34be8c                  blessed to be living sundayvibes    \n\n              emotion identification  \n0        anticipation          train  \n1             sadness          train  \n2                fear          train  \n3                 joy          train  \n4        anticipation          train  \n...               ...            ...  \n1455558           joy          train  \n1455559           joy          train  \n1455560           joy          train  \n1455561           joy          train  \n1455562           joy          train  \n\n[1455563 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n      <th>emotion</th>\n      <th>identification</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x376b20</td>\n      <td>people who post add me on snapchat must be deh...</td>\n      <td>anticipation</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x2d5350</td>\n      <td>@brianklaas as we see trump is dangerous to fr...</td>\n      <td>sadness</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x1cd5b0</td>\n      <td>now issa is stalking tasha 😂😂😂</td>\n      <td>fear</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x1d755c</td>\n      <td>@riskshow @thekevinallison thx for the best ti...</td>\n      <td>joy</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x2c91a8</td>\n      <td>still waiting on those supplies liscus</td>\n      <td>anticipation</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455558</th>\n      <td>0x321566</td>\n      <td>im so happy nowonder the name of this show hap...</td>\n      <td>joy</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1455559</th>\n      <td>0x38959e</td>\n      <td>in every circumtance id like to be thankful to...</td>\n      <td>joy</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1455560</th>\n      <td>0x2cbca6</td>\n      <td>theres currently two girls walking around the ...</td>\n      <td>joy</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1455561</th>\n      <td>0x24faed</td>\n      <td>ah corporate life where you can date  using ju...</td>\n      <td>joy</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1455562</th>\n      <td>0x34be8c</td>\n      <td>blessed to be living sundayvibes</td>\n      <td>joy</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>1455563 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the train dataframe\n",
    "train_df = pd.merge(tweets_dm, emotion, on='tweet_id', how='inner')\n",
    "train_df = pd.merge(train_df, data_identification, on='tweet_id', how='inner')\n",
    "train_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_dtm = tfidf_vect.fit(train_df['text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['aa', 'aaa', 'aaaa', ..., '𝖒𝖊𝖉𝖎𝖈𝖎𝖓𝖊', '𝖔𝖓', '𝖙𝖍𝖊'], dtype=object)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check terms\n",
    "tfidf_vect.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Machine Learning Modelling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "          index  tweet_id                                               text\n0             2  0x28b412  confident of your obedience i write to you kno...\n1             4  0x2de201  trust is not the same as faith a friend is som...\n2             9  0x218443  when do you have enough  when are you satisfie...\n3            30  0x2939d5  god woke you up now chase the day godsplan god...\n4            33  0x26289a  in these tough times who do you turn to as you...\n...         ...       ...                                                ...\n411967  1867525  0x2913b4  for this is the message that ye heard from the...\n411968  1867529  0x2a980e  there is a lad here which hath five barley loa...\n411969  1867530  0x316b80  when you buy the last  tickets remaining for a...\n411970  1867531  0x29d0cb  i swear all this hard work gone pay off one da...\n411971  1867532  0x2a6a4f  @parcelgo no card left when i wasnt in so i ha...\n\n[411972 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>tweet_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0x28b412</td>\n      <td>confident of your obedience i write to you kno...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>0x2de201</td>\n      <td>trust is not the same as faith a friend is som...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9</td>\n      <td>0x218443</td>\n      <td>when do you have enough  when are you satisfie...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30</td>\n      <td>0x2939d5</td>\n      <td>god woke you up now chase the day godsplan god...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33</td>\n      <td>0x26289a</td>\n      <td>in these tough times who do you turn to as you...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>411967</th>\n      <td>1867525</td>\n      <td>0x2913b4</td>\n      <td>for this is the message that ye heard from the...</td>\n    </tr>\n    <tr>\n      <th>411968</th>\n      <td>1867529</td>\n      <td>0x2a980e</td>\n      <td>there is a lad here which hath five barley loa...</td>\n    </tr>\n    <tr>\n      <th>411969</th>\n      <td>1867530</td>\n      <td>0x316b80</td>\n      <td>when you buy the last  tickets remaining for a...</td>\n    </tr>\n    <tr>\n      <th>411970</th>\n      <td>1867531</td>\n      <td>0x29d0cb</td>\n      <td>i swear all this hard work gone pay off one da...</td>\n    </tr>\n    <tr>\n      <th>411971</th>\n      <td>1867532</td>\n      <td>0x2a6a4f</td>\n      <td>@parcelgo no card left when i wasnt in so i ha...</td>\n    </tr>\n  </tbody>\n</table>\n<p>411972 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the test dataframe\n",
    "test_df = pd.merge(tweets_dm, data_identification, on='tweet_id', how='inner')\n",
    "test_df = test_df[test_df['identification']=='test']\n",
    "test_df = test_df[['tweet_id', 'text']]\n",
    "test_df = test_df.reset_index()\n",
    "\n",
    "# Save to pickle\n",
    "train_df.to_pickle(\"kaggle_train_df.pkl\")\n",
    "test_df.to_pickle(\"kaggle_test_df.pkl\")\n",
    "test_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 19.9min finished\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "x_train = tfidf_dtm.transform(train_df['text'])\n",
    "y_train = train_df['emotion']\n",
    "x_test = tfidf_dtm.transform(test_df['text'])\n",
    "\n",
    "# MNB_model = MultinomialNB()\n",
    "# MNB_model = MNB_model.fit(x_train, y_train)\n",
    "# LSVC_model = LinearSVC(verbose=True)\n",
    "# LSVC_model = LSVC_model.fit(x_train, y_train)\n",
    "LR_model = LogisticRegression(max_iter=850, n_jobs=-1, verbose=True)\n",
    "LR_model = LR_model.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "# SGDC_model = SGDClassifier(max_iter=4000)\n",
    "# SGDC_model = SGDC_model.fit(x_train, y_train)\n",
    "# RBFS_model = RBFSampler()\n",
    "# RBFS_model = RBFS_model.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Analyze & Generate the Result\n",
    "\n",
    "Sometimes the result of the training accuracy doesn't fully reflect the test accuracy. For example:\n",
    "\n",
    "- Using Linear Support Vector Classifier, we got 77% Training accuracy, however our test is 45.5%\n",
    "- Using Logistic Regression, we got 68% accuracy, however the test accuracy is higher 46%\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6282943438380888\n"
     ]
    }
   ],
   "source": [
    "# Get traaining accuracy of the model\n",
    "selected_model = LR_model\n",
    "y_train_predict = selected_model.predict(x_train)\n",
    "y_test_predict = selected_model.predict(x_test)\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, y_train_predict)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "             emotion\n0       anticipation\n1       anticipation\n2                joy\n3       anticipation\n4              trust\n...              ...\n411967  anticipation\n411968  anticipation\n411969       sadness\n411970         anger\n411971       sadness\n\n[411972 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>anticipation</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>anticipation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>anticipation</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trust</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>411967</th>\n      <td>anticipation</td>\n    </tr>\n    <tr>\n      <th>411968</th>\n      <td>anticipation</td>\n    </tr>\n    <tr>\n      <th>411969</th>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>411970</th>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>411971</th>\n      <td>sadness</td>\n    </tr>\n  </tbody>\n</table>\n<p>411972 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate data frame for the prediction\n",
    "y_test_predict = pd.DataFrame(y_test_predict, columns = ['emotion'])\n",
    "y_test_predict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "              id       emotion\n0       0x28b412  anticipation\n1       0x2de201  anticipation\n2       0x218443           joy\n3       0x2939d5  anticipation\n4       0x26289a         trust\n...          ...           ...\n411967  0x2913b4  anticipation\n411968  0x2a980e  anticipation\n411969  0x316b80       sadness\n411970  0x29d0cb         anger\n411971  0x2a6a4f       sadness\n\n[411972 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x28b412</td>\n      <td>anticipation</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x2de201</td>\n      <td>anticipation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x218443</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x2939d5</td>\n      <td>anticipation</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x26289a</td>\n      <td>trust</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>411967</th>\n      <td>0x2913b4</td>\n      <td>anticipation</td>\n    </tr>\n    <tr>\n      <th>411968</th>\n      <td>0x2a980e</td>\n      <td>anticipation</td>\n    </tr>\n    <tr>\n      <th>411969</th>\n      <td>0x316b80</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>411970</th>\n      <td>0x29d0cb</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>411971</th>\n      <td>0x2a6a4f</td>\n      <td>sadness</td>\n    </tr>\n  </tbody>\n</table>\n<p>411972 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename column to meet Kaggle specification\n",
    "submit_df = test_df.assign(emotion=y_test_predict)\n",
    "submit_df = submit_df[['tweet_id', 'emotion']]\n",
    "submit_df = submit_df.rename(columns={'tweet_id': 'id'})\n",
    "submit_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Create CSV file of test dataset emotion prediction\n",
    "submit_df.to_csv('submit.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Conclusion and Improvement\n",
    "\n",
    "- JSON object separated with new line: use parameter ```lines=True```\n",
    "- tweet_DM.json is nested JSON (has hierarchy) separated with multiline -> need to transform into non-hierarchy, using json.load to read per line\n",
    "    - Solve multiline: use json.load and iterate perline to create normal JSON\n",
    "    - Solve nested issue: use pd.json_normalize, rename the column for better readability\n",
    "\n",
    "Based on the process and results in this assignment, there are several improvement points that can be considered in the future:\n",
    "- Since we are working on a dataset with varying language, a translation library or API can be considered to standardize the text\n",
    "- Other way to work with the data is to classify the language in each text and create different training model for each language\n",
    "- We can provide more text pre-processing by using Regular Expression\n",
    "- Convert emoji into text\n",
    "- Improve the Lemmatization process by considering more robust pos-tag\n",
    "- Try deep learning or language model such as Transformers, BERT"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
